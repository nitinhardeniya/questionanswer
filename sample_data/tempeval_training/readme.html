<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"><html><head><style type="text/css"><!--body {   font-size: 12pt;   line-height: 14pt;  margin: 10pt }p {   font-size: 12pt }code {   font-size: 11pt }--></style><title>TempEval Final Training Data</title><meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"></head><body><h1>TempEval Final Training Data</h1>February 26th, 2007<hr><p>This document describes the TempEval data, the way they werecreated, and the validation and scoring scripts that are bundled withthe data. If needed, updates to this document will be posted onthe <a href="http://timeml.org/tempeval/">TempEval</a> website and onthe TempEval Google group and mailing list (see the TempEval websiteon how to join the mailing list). This document does not replace thetask description on the <a href="http://nlp.cs.swarthmore.edu/semeval/tasks/task15/description.shtml">SemEval</a>and <a href="http://timeml.org/tempeval/">TempEval</a> websites, but complements it.<h3>Data Description</h3>The TempEval annotation language is a simplified versionof <a href="http://timeml.org/">TimeML</a>.  TheTimeML <a href="docs/timeml_1.2.1.html">specifications</a>,<a href="docs/annguide_1.2.1.pdf">annotation guidelines</a> and<a href="docs/timeml_1.2.1.dtd" type="text/plain">document typedefinition</a> (all for TimeML version 1.2.1) are included here foreasy reference. For TempEval, we use the following five tags:<dl><dt>&lt;TempEval&gt;<dd>The document root.</dl><dl><dt>&lt;s&gt;<dd>The sentence tag. All sentence tags in the TempEval data areautomatically created using the Alembic Natural Language processingtools. A sentence tag can contain TIMEX3 tags andEVENT tags, but no TLINK tags.</dl><dl><dt>&lt;TIMEX3&gt;<dd>Tags the time expressions in the text. It is identical to theTIMEX3 tag in TimeML. See theTimeML <a href="docs/timeml_1.2.1.html">specifications</a>and <a href="docs/annguide_1.2.1.pdf">guidelines</a> for furtherdetails on this tag and its attributes. Each document has one specialTIMEX3 tag, the Document Creation Time, which is interpreted as aninterval that spans the whole day.</dl><dl><dt>&lt;EVENT&gt;<dd>Tags the events in the text. The TempEval EVENT merges theinformation on two TimeML tags: EVENT and MAKEINSTANCE. TimeML usedthese two tags to refer to two instances of an event in sentences like"He taught on Wednesday and Friday". This complication was notnecessary for the TempEval data. Both tags and their attributes aredescribed in theTimeML <a href="docs/timeml_1.2.1.html">specifications</a>and <a href="docs/annguide_1.2.1.pdf">guidelines</a>. For TempEvaltask C, one extra attribute is added: <tt>mainevent</tt>, withpossible values <tt>YES</tt> and <tt>NO</tt>.</dl><dl><dt>&lt;TLINK&gt;<dd>A simplified version of the TimeML TLINK tag. The relationtypes for the TimeML version form a fine-grained set based on JamesAllen's interval logic (James Allen, "Maintaining Knowledge aboutTemporal Intervals." Communications of the ACM 26, 11, 832-843,November 1983). For TempEval, we only use three relations as well asthree disjunctions over those three: BEFORE, OVERLAP, AFTER,BEFORE-OR-OVERLAP, OVERLAP-OR-AFTER, and VAGUE. Here, OVERLAP refersto two events (or an event and a time interval) that have a non-emptyoverlap. VAGUE is used for those cases where no particular relationcan be established.</dl>The training data contain all TLINKS required by tasks A, B and C. Inaddition, the training data contain all event and timex information,including, for task C, markers to indicate main events for each sentence. Recall that tasks A and B areconstrained to linking events from the event target list. The eventtarget list consists of those events that occur 20 times or more inthe corpus. A complete listof <a href="docs/stem_frequencies.txt">stems</a> ordered on frequencyis included in the <tt>docs</tt> directory (only stems occurringmore than once are added to the list).<p>The data directory has two sub directories, one with the data fortasks A and B, with 162 documents, and one with data for task C, with163 documents. This discrepancy is due to one document where theDocument Creation Time was placed in the future, which makes task Brather hard to do. This document was removed from the training set.<h3>Test Data</h3>The test data are distributed separately from the training data. Theformat of the test data is identical to the format of the trainingdata. But there are two differences in the actual content:<ol><li>the test data is comprised of a different documents set<li>all relation types of TLINKs in test documents are set to UNKNOWN</ol><h3>Annotation Procedure</h3>The EVENT and TIMEX3 annotation were taken from TimeBank(<code>http://timeml.org/site/timebank/timebank.html</code>). Theannotation procedure for TLINKs includes dual annotation by sevenannotators using a web-based annotation interface(see <a href="docs/screenshot.html">the screen shot page</a> for moredetails). After this phase, two experienced annotators looked at alloccurrences where two annotators differed as to what relation type toselect. For task C, there was an extra annotation phase where the mainevents wereselected. <a href="docs/mainevent-guidelines-v2.html">Annotationguidelines</a> for main event annotation are included in thisdistribution.<h3>Validation</h3>Included with the trial data are a <a href="validation/validate.pl"type="text/plain">Perl validation script</a> anda <a href="validation/tempeval.dtd" type="text/plain">Document TypeDefinition</a> for TempEval annotation. All files in the training sethave been validatated. To validate TempEval files using the DTD,open a terminal window (Linux/Unix/MacOSX) or a command prompt(Windows) and type the following:<blockquote><code>% perl validate.pl ../data/taskAB</code><br><code>% perl validate.pl ../data/taskC</code></blockquote>This will write validation errors and warnings to the standardoutput. All lines with <tt>INFO-300</tt> can be ignored, ingeneral, they report on reference counts. On Unix/Linux systems, theselines can be filtered out by using:<blockquote><code>% perl validate.pl ../data/taskAB | grep -v INFO-300 </code><br><code>% perl validate.pl ../data/taskC | grep -v INFO-300 </code></blockquote><p> The script assumes the Perl modules XML::Checker and XML::RegExp,both available at CPAN (<a href="http://www.cpan.org">http://www.cpan.org</a>).<h3>Evaluation</h3>Also included with the training data isa <a href="scripts/scoreTLINKS.pl" type="text/plain">Perl scoringscript</a>. It measures precision and recall using a strict and arelaxed scoring scheme. Seethe <a href="docs/evaluation.pdf">evaluation document</a> inthe <tt>docs</tt> directory for more details.</body></html>